"""
Semantic Search Service
Service x·ª≠ l√Ω logic t√¨m ki·∫øm ng·ªØ nghƒ©a (semantic search) v·ªõi vector embeddings
K·∫øt h·ª£p v·ªõi filter theo danh s√°ch ID t·ª´ PostGIS
"""
import time
from datetime import datetime
from typing import Optional
from radius_logic.route import RouteBuilder
from retrieval.embeddings import EmbeddingGenerator
from typing import List, Dict, Any, Tuple
from radius_logic.information_location import LocationInfoService
from retrieval.qdrant_vector_store import QdrantVectorStore
from qdrant_client.models import Filter, FieldCondition, MatchAny
from utils.time_utils import TimeUtils


class SemanticSearchService:
    """Service x·ª≠ l√Ω logic t√¨m ki·∫øm ng·ªØ nghƒ©a"""
    
    def __init__(self):
        """Kh·ªüi t·∫°o service v·ªõi Qdrant v√† Embedding generator"""
        self.vector_store = QdrantVectorStore()
        self.embedder = EmbeddingGenerator()
        self.route_builder = RouteBuilder()
        self.location_info_service = LocationInfoService()
    
    def search_by_query(self, query: str, top_k: int = 10) -> Dict[str, Any]:
        """
        T√¨m ki·∫øm ƒë·ªãa ƒëi·ªÉm theo query ng·ªØ nghƒ©a (kh√¥ng filter ID)
        
        Args:
            query: C√¢u query t√¨m ki·∫øm (vd: "Travel", "Nature & View")
            top_k: S·ªë l∆∞·ª£ng k·∫øt qu·∫£ tr·∫£ v·ªÅ t·ªëi ƒëa
            
        Returns:
            Dict ch·ª©a k·∫øt qu·∫£ v·ªõi c√°c tr∆∞·ªùng:
            - status: "success" ho·∫∑c "error"
            - query: query ƒë√£ t√¨m ki·∫øm
            - total_results: s·ªë l∆∞·ª£ng k·∫øt qu·∫£
            - execution_time_seconds: th·ªùi gian th·ª±c thi
            - results: danh s√°ch ƒë·ªãa ƒëi·ªÉm v·ªõi score t∆∞∆°ng ƒë·ªìng
        """
        try:
            # ƒêo th·ªùi gian
            start_time = time.time()
            
            # 1. Sinh embedding cho query
            print(f"Generating embedding for query: {query}")
            embed_start = time.time()
            query_embedding = self.embedder.generate_single_embedding(query)
            embed_time = time.time() - embed_start
            
            # 2. T√¨m ki·∫øm trong Qdrant (kh√¥ng filter)
            print(f"Searching in Qdrant for top {top_k} results...")
            search_start = time.time()
            search_results = self.vector_store.search(
                query_embedding=query_embedding,
                k=top_k
         )
            search_time = time.time() - search_start
            
            total_time = time.time() - start_time
            print(f"‚è±Ô∏è  search_by_query executed in {total_time:.3f}s (Embed: {embed_time:.3f}s + Search: {search_time:.3f}s)")
            print(f"Search returned {len(search_results) if search_results else 0} results")
            
            # Ki·ªÉm tra n·∫øu k·∫øt qu·∫£ r·ªóng
            if not search_results:
                print("‚ö†Ô∏è No results found")
                return {
                    "status": "success",
                    "query": query,
                    "total_results": 0,
                    "execution_time_seconds": round(total_time, 3),
                    "timing_breakdown": {
                        "embedding_seconds": round(embed_time, 3),
                        "search_seconds": round(search_time, 3)
                    },
                    "results": []
                }
            
            # 3. L·∫•y location IDs t·ª´ Qdrant results
            location_ids = [hit.id for hit in search_results]  # hit.id l√† point.id
            print(f"Fetching {len(location_ids)} location details from DB...")
            
            # 4. Query DB ƒë·ªÉ l·∫•y th√¥ng tin ƒë·∫ßy ƒë·ªß
            db_start = time.time()
            locations_map = self.location_info_service.get_locations_by_ids(location_ids)
            db_time = time.time() - db_start
            print(f"DB query took {db_time:.3f}s")
            
            # 5. Merge semantic score v·ªõi location info
            results = []
            for hit in search_results:
                location_info = locations_map.get(hit.id)
                if location_info:
                    result = {
                        "score": hit.score,
                        **location_info  # Merge t·∫•t c·∫£ fields t·ª´ DB (bao g·ªìm poi_type)
                    }
                    results.append(result)
                else:
                    print(f"‚ö†Ô∏è Location {hit.id} not found in DB")
            
            return {
                "status": "success",
                "query": query,
                "total_results": len(results),
                "execution_time_seconds": round(total_time, 3),
                "timing_breakdown": {
                    "embedding_seconds": round(embed_time, 3),
                    "search_seconds": round(search_time, 3)
                },
                "results": results
            }
            
        except Exception as e:
            return {
                "status": "error",
                "error": str(e),
                "query": query,
                "total_results": 0,
                "results": []
            }
    
    def search_by_query_with_filter(
        self,
        query: str,
        id_list: List[str],
        top_k: int = 10,
        spatial_results: Optional[List[Dict[str, Any]]] = None
    ) -> Dict[str, Any]:
        """
        T√¨m ki·∫øm ƒë·ªãa ƒëi·ªÉm theo query ng·ªØ nghƒ©a v·ªõi filter ID (d√πng cho combined search)
        
        Args:
            query: C√¢u query t√¨m ki·∫øm
            id_list: Danh s√°ch ID c·∫ßn filter
            top_k: S·ªë l∆∞·ª£ng k·∫øt qu·∫£
            
        Returns:
            Dict ch·ª©a k·∫øt qu·∫£
        """
        try:
            start_time = time.time()
            
            if not id_list or len(id_list) == 0:
                return {
                    "status": "error",
                    "error": "Empty ID list provided",
                    "query": query,
                    "total_results": 0,
                    "results": []
                }
            
            print(f"Generating embedding for query: {query}")
            embed_start = time.time()
            query_embedding = self.embedder.generate_single_embedding(query)
            embed_time = time.time() - embed_start
            
            print(f"Searching in Qdrant with {len(id_list)} point IDs filter...")
            qdrant_start = time.time()
            # Light RAG: ch·ªâ l·∫•y id + score t·ª´ Qdrant (with_payload=False)
            search_results = self.vector_store.search_by_ids(
                query_embedding=query_embedding,
                point_ids=id_list,
                k=top_k,
                with_payload=False,  # Ch·ªâ l·∫•y id+score ‚Üí nhanh h∆°n
                hnsw_ef=32  # Gi·∫£m ef ƒë·ªÉ tƒÉng t·ªëc (trade-off: ƒë·ªô ch√≠nh x√°c gi·∫£m ~2%)
            )
            qdrant_time = time.time() - qdrant_start
            
            execution_time = time.time() - start_time
            print(f"‚è±Ô∏è  Embedding: {embed_time:.3f}s, Qdrant search: {qdrant_time:.3f}s")
            
            if not search_results or not isinstance(search_results, list):
                return {
                    "status": "success",
                    "query": query,
                    "filter_ids_count": len(id_list),
                    "total_results": 0,
                    "execution_time_seconds": round(execution_time, 3),
                    "results": []
                }
            
            # L·∫•y location IDs t·ª´ Qdrant results (point.id)
            location_ids = [hit.id for hit in search_results]
            print(f"Mapping {len(location_ids)} locations from spatial_results...")
            
            # D√πng tr·ª±c ti·∫øp spatial_results (ƒë√£ c√≥ full data t·ª´ find_nearest_locations)
            fetch_start = time.time()
            location_id_set = set(location_ids)
            locations_map = {
                item["id"]: item
                for item in (spatial_results or [])
                if item["id"] in location_id_set
            }
            fetch_time = time.time() - fetch_start
            print(f"‚è±Ô∏è  Data mapping: {fetch_time:.3f}s ({len(locations_map)}/{len(location_ids)} found)")
            
            # Merge semantic score v·ªõi location info
            results = []
            for hit in search_results:
                location_info = locations_map.get(hit.id)
                if location_info:
                    result = {
                        "score": hit.score,
                        **location_info  # Merge fields
                    }
                    results.append(result)
                else:
                    print(f"‚ö†Ô∏è Location {hit.id} not found")
            
            return {
                "status": "success",
                "query": query,
                "filter_ids_count": len(id_list),
                "total_results": len(results),
                "execution_time_seconds": round(execution_time, 3),
                "timing_detail": {
                    "embedding_seconds": round(embed_time, 3),
                    "qdrant_search_seconds": round(qdrant_time, 3),
                    "data_fetch_seconds": round(fetch_time, 3)
                },
                "results": results
            }
            
        except Exception as e:
            return {
                "status": "error",
                "error": str(e),
                "query": query,
                "total_results": 0,
                "results": []
            }
    
    def search_combined(
        self,
        latitude: float,
        longitude: float,
        transportation_mode: str,
        semantic_query: str,
        top_k_semantic: int = 10
    ) -> Dict[str, Any]:
        """
        T√¨m ki·∫øm k·∫øt h·ª£p: Spatial search (PostGIS) + Semantic search (Qdrant)
        
        Workflow:
        1. T√¨m ki·∫øm T·∫§T C·∫¢ ƒë·ªãa ƒëi·ªÉm g·∫ßn (>= 50) theo t·ªça ƒë·ªô v√† ph∆∞∆°ng ti·ªán (PostGIS)
        2. L·∫•y danh s√°ch ID t·ª´ k·∫øt qu·∫£ b∆∞·ªõc 1
        3. T√¨m ki·∫øm semantic trong danh s√°ch ID ƒë√≥, tr·∫£ v·ªÅ top_k_semantic k·∫øt qu·∫£ c√≥ similarity cao nh·∫•t
        
        Args:
            latitude: Vƒ© ƒë·ªô
            longitude: Kinh ƒë·ªô
            transportation_mode: Ph∆∞∆°ng ti·ªán di chuy·ªÉn
            semantic_query: Query ng·ªØ nghƒ©a (vd: "Travel", "Nature & View")
            top_k_semantic: S·ªë l∆∞·ª£ng k·∫øt qu·∫£ semantic cu·ªëi c√πng (m·∫∑c ƒë·ªãnh 10)
            
        Returns:
            Dict ch·ª©a CH·ªà top_k_semantic ƒë·ªãa ƒëi·ªÉm c√≥ similarity cao nh·∫•t
        """
        from services.location_service import LocationService
        from config.config import Config
        
        try:
            # ƒêo t·ªïng th·ªùi gian
            total_start = time.time()
            
            # 1. T√¨m ki·∫øm spatial
            print(f"\nüîç Step 1: Spatial search...")
            location_service = LocationService(Config.get_db_connection_string())
            spatial_results = location_service.find_nearest_locations(
                latitude=latitude,
                longitude=longitude,
                transportation_mode=transportation_mode
            )
            
            if spatial_results["status"] != "success":
                return {
                    "status": "error",
                    "error": "Spatial search failed",
                    "spatial_error": spatial_results.get("error"),
                    "results": []
                }
            # print(len(spatial_results["results"]))    
            # 2. L·∫•y danh s√°ch ID t·ª´ spatial results
            id_list = [loc["id"] for loc in spatial_results["results"]]
            
            if not id_list:
                return {
                    "status": "success",
                    "message": "No locations found in spatial search",
                    "query": semantic_query,
                    "spatial_info": {
                        "radius_used": spatial_results.get("radius_used"),
                        "total_spatial_locations": 0
                    },
                    "total_results": 0,
                    "results": []
                }
            
            # 3. T√¨m ki·∫øm semantic trong danh s√°ch ID
            print(f"\nüîç Step 2: Semantic search in {len(id_list)} locations...")
            semantic_start = time.time()
            semantic_results = self.search_by_query_with_filter(
                query=semantic_query,
                id_list=id_list,
                top_k=top_k_semantic,
                spatial_results = spatial_results["results"]
            )
            semantic_time = time.time() - semantic_start
            
            # Semantic results ƒë√£ c√≥ ƒë·∫ßy ƒë·ªß th√¥ng tin t·ª´ DB (bao g·ªìm rating)
            # Kh√¥ng c·∫ßn merge rating t·ª´ spatial results n·ªØa
            
            total_time = time.time() - total_start
            spatial_time = spatial_results.get("execution_time_seconds", 0)
            
            # L·∫•y timing detail t·ª´ semantic search
            semantic_timing = semantic_results.get("timing_detail", {})
            
            print(f"\n‚è±Ô∏è  Timing breakdown:")
            print(f"   ‚Ä¢ Spatial search: {spatial_time:.3f}s")
            print(f"   ‚Ä¢ Embedding: {semantic_timing.get('embedding_seconds', 0):.3f}s")
            print(f"   ‚Ä¢ Qdrant search: {semantic_timing.get('qdrant_search_seconds', 0):.3f}s")
            print(f"   ‚Ä¢ DB query: {semantic_timing.get('db_query_seconds', 0):.3f}s")
            print(f"   ‚Ä¢ Total: {total_time:.3f}s")
            
            # Tr·∫£ v·ªÅ CH·ªà semantic results (top_k_semantic ƒë·ªãa ƒëi·ªÉm c√≥ similarity cao nh·∫•t) + rating
            return {
                "status": "success",
                "query": semantic_query,
                "spatial_info": {
                    "transportation_mode": spatial_results.get("transportation_mode"),
                    "radius_used": spatial_results.get("radius_used"),
                    "total_spatial_locations": len(id_list),
                    "spatial_execution_time": spatial_results.get("execution_time_seconds")
                },
                "total_results": semantic_results.get("total_results", 0),
                "total_execution_time_seconds": round(total_time, 3),
                "timing_detail": semantic_timing,  # Pass through timing detail
                "results": semantic_results.get("results", [])
            }
            
        except Exception as e:
            return {
                "status": "error",
                "error": str(e),
                "results": []
            }
    
    def search_combined_multi_queries(
        self,
        latitude: float,
        longitude: float,
        transportation_mode: str,
        semantic_query: str,
        top_k_semantic: int = 10,
        customer_like: bool = False,
        current_datetime: Optional[datetime] = None,
        max_time_minutes: Optional[int] = None
    ) -> Dict[str, Any]:
        """
        T√¨m ki·∫øm k·∫øt h·ª£p v·ªõi h·ªó tr·ª£ nhi·ªÅu queries ph√¢n c√°ch b·∫±ng d·∫•u ph·∫©y
        M·ªói query s·∫Ω truy xu·∫•t Qdrant ri√™ng v√† l·∫•y top 10, ƒë√°nh d·∫•u category
        C√≥ th·ªÉ l·ªçc theo th·ªùi gian m·ªü c·ª≠a
        
        Args:
            latitude: Vƒ© ƒë·ªô
            longitude: Kinh ƒë·ªô
            transportation_mode: Ph∆∞∆°ng ti·ªán di chuy·ªÉn
            semantic_query: Query ng·ªØ nghƒ©a (c√≥ th·ªÉ nhi·ªÅu queries ph√¢n c√°ch b·∫±ng ,)
            top_k_semantic: S·ªë l∆∞·ª£ng k·∫øt qu·∫£ m·ªói query (m·∫∑c ƒë·ªãnh 10)
            customer_like: T·ª± ƒë·ªông th√™m "Culture & heritage" n·∫øu ch·ªâ c√≥ "Food & Local Flavours"
            current_datetime: Th·ªùi ƒëi·ªÉm hi·ªán t·∫°i c·ªßa user (None = kh√¥ng l·ªçc)
            max_time_minutes: Th·ªùi gian t·ªëi ƒëa user c√≥ (None = kh√¥ng l·ªçc)
            
        Returns:
            Dict ch·ª©a t·∫•t c·∫£ POI t·ª´ c√°c queries, m·ªói POI c√≥ th√™m field 'category'
        """
        from services.location_service import LocationService
        from config.config import Config
        
        try:
            total_start = time.time()
            
            # Split queries b·∫±ng d·∫•u ph·∫©y v√† trim whitespace
            original_queries = [q.strip() for q in semantic_query.split(',') if q.strip()]

            # Lu√¥n m·ªü r·ªông "Food & Local Flavours" th√†nh ["Cafe & Bakery", "Restaurant"]
            queries = []
            for q in original_queries:
                if q == "Food & Local Flavours":
                    queries.extend(["Cafe & Bakery", "Restaurant"])
                else:
                    queries.append(q)
            
            # N·∫øu customer_like=True v√† input ban ƒë·∫ßu CH·ªà c√≥ 1 query l√† "Food & Local Flavours", t·ª± ƒë·ªông th√™m "Culture & heritage"
            if customer_like:
                if len(original_queries) == 1 and original_queries[0] == "Food & Local Flavours":
                    if "Culture & heritage" not in queries:
                        queries.append("Culture & heritage")
                        print(f"‚ú® CustomerLike=True + single 'Food & Local Flavours' ‚Üí T·ª± ƒë·ªông th√™m 'Culture & heritage'")
            
            # üçΩÔ∏è MEAL TIME LOGIC: T·ª± ƒë·ªông th√™m Restaurant n·∫øu c√≥ overlap v·ªõi meal times
            if current_datetime and max_time_minutes:
                meal_check = TimeUtils.check_overlap_with_meal_times(current_datetime, max_time_minutes)
                
                # N·∫øu c·∫ßn restaurant v√† user kh√¥ng ch·ªçn Food & Local Flavours
                if meal_check["needs_restaurant"] and "Food & Local Flavours" not in original_queries:
                    if "Restaurant" not in queries:
                        queries.append("Restaurant")
                        print(f"üçΩÔ∏è  T·ª± ƒë·ªông th√™m 'Restaurant' v√¨ overlap {meal_check['lunch_overlap_minutes']}m lunch / {meal_check['dinner_overlap_minutes']}m dinner")

            
            if not queries:
                return {
                    "status": "error",
                    "error": "No valid queries provided",
                    "results": []
                }
            
            print(f"\nüîç Processing {len(queries)} queries: {queries}")
            
            # 1. Spatial search (ch·ªâ 1 l·∫ßn) v·ªõi t√πy ch·ªçn l·ªçc theo th·ªùi gian
            print(f"\nüîç Step 1: Spatial search...")
            location_service = LocationService(Config.get_db_connection_string())
            spatial_results = location_service.find_nearest_locations(
                latitude=latitude,
                longitude=longitude,
                transportation_mode=transportation_mode,
                current_datetime=current_datetime,
                max_time_minutes=max_time_minutes
            )
            
            if spatial_results["status"] != "success":
                return {
                    "status": "error",
                    "error": "Spatial search failed",
                    "spatial_error": spatial_results.get("error"),
                    "results": []
                }
            
            id_list = [loc["id"] for loc in spatial_results["results"]]
            
            if not id_list:
                return {
                    "status": "success",
                    "message": "No locations found in spatial search",
                    "query": semantic_query,
                    "spatial_info": {
                        "radius_used": spatial_results.get("radius_used"),
                        "total_spatial_locations": 0
                    },
                    "results": []
                }
            
            # 2. Semantic search cho t·ª´ng query
            # D√πng dict ƒë·ªÉ track POI t·ªët nh·∫•t cho m·ªói ID (ch·ªçn similarity cao nh·∫•t)
            poi_best_match = {}  # {place_id: {"place": place_dict, "similarity": score, "category": ..., "category_index": ...}}
            
            # Track timing v√† s·ªë POI c·ªßa t·ª´ng query
            query_details = []  # [{"query": str, "pois_count": int, "time_seconds": float, "embedding_seconds": float, "qdrant_seconds": float}]
            total_embedding_time = 0
            total_qdrant_time = 0
            
            for idx, query in enumerate(queries):
                print(f"\nüîç Step 2.{idx+1}: Semantic search for '{query}'...")
                semantic_start = time.time()
                
                semantic_results = self.search_by_query_with_filter(
                    query=query,
                    id_list=id_list,
                    top_k=top_k_semantic,
                    spatial_results=spatial_results["results"]
                )
                
                semantic_time = time.time() - semantic_start
                
                # L·∫•y timing detail t·ª´ k·∫øt qu·∫£
                timing_detail = semantic_results.get("timing_detail", {})
                embed_time = timing_detail.get("embedding_seconds", 0)
                qdrant_time = timing_detail.get("qdrant_search_seconds", 0)
                
                total_embedding_time += embed_time
                total_qdrant_time += qdrant_time
                
                results_count = len(semantic_results.get('results', []))
                print(f"   Query '{query}' took {semantic_time:.3f}s, found {results_count} results")
                
                # Track detail c·ªßa query n√†y
                query_details.append({
                    "query": query,
                    "pois_count": results_count,
                    "time_seconds": round(semantic_time, 3),
                    "embedding_seconds": round(embed_time, 3),
                    "qdrant_search_seconds": round(qdrant_time, 3)
                })
                
                # V·ªõi m·ªói POI, ch·ªâ gi·ªØ l·∫°i option c√≥ similarity cao nh·∫•t
                for place in semantic_results.get('results', []):
                    place_id = place.get('id')
                    current_similarity = place.get('score', 0.0)
                    
                    if place_id not in poi_best_match:
                        # L·∫ßn ƒë·∫ßu g·∫∑p POI n√†y
                        poi_best_match[place_id] = {
                            "place": place,
                            "similarity": current_similarity,
                            "category": query,
                            "category_index": idx
                        }
                    else:
                        # ƒê√£ c√≥ r·ªìi, so s√°nh similarity
                        existing_similarity = poi_best_match[place_id]["similarity"]
                        if current_similarity > existing_similarity:
                            # Similarity m·ªõi cao h∆°n -> thay th·∫ø
                            poi_best_match[place_id] = {
                                "place": place,
                                "similarity": current_similarity,
                                "category": query,
                                "category_index": idx
                            }
            
            # Chuy·ªÉn dict v·ªÅ list v√† g√°n category
            all_results = []
            for place_id, data in poi_best_match.items():
                place = data["place"]
                place['category'] = data["category"]
                place['category_index'] = data["category_index"]
                all_results.append(place)
                # ki·ªÉm tra xem th√™m v√†o ƒë√∫ng ch∆∞a
                # print(f" - Place ID {place_id} assigned to category '{data['category']}' with similarity {data['similarity']:.4f}")
            
            total_time = time.time() - total_start
            
            print(f"\n‚úÖ Total: {len(all_results)} unique POIs from {len(queries)} queries in {total_time:.3f}s")
            print(f"   (M·ªói POI ch·ªâ thu·ªôc 1 category c√≥ similarity cao nh·∫•t)")
            
            return {
                "status": "success",
                "query": semantic_query,
                "queries_count": len(queries),
                "query_details": query_details,  # Th√™m th√¥ng tin chi ti·∫øt m·ªói query
                "spatial_info": {
                    "transportation_mode": spatial_results.get("transportation_mode"),
                    "radius_used": spatial_results.get("radius_used"),
                    "total_spatial_locations": len(id_list),
                    "spatial_execution_time": spatial_results.get("execution_time_seconds")
                },
                "total_results": len(all_results),
                "total_execution_time_seconds": round(total_time, 3),
                "timing_detail": {
                    "embedding_seconds": round(total_embedding_time, 3),
                    "qdrant_search_seconds": round(total_qdrant_time, 3)
                },
                "results": all_results
            }
            
        except Exception as e:
            return {
                "status": "error",
                "error": str(e),
                "results": []
            }
    
    def search_combined_with_routes(
        self,
        latitude: float,
        longitude: float,
        transportation_mode: str,
        semantic_query: str,
        max_time_minutes: int = 180,
        target_places: int = 5,
        max_routes: int = 3,
        top_k_semantic: int = 10,
        customer_like: bool = False,
        current_datetime: Optional[datetime] = None
    ) -> Dict[str, Any]:
        """
        T√¨m ki·∫øm k·∫øt h·ª£p + X√¢y d·ª±ng l·ªô tr√¨nh v·ªõi t√πy ch·ªçn l·ªçc theo th·ªùi gian m·ªü c·ª≠a
        
        Workflow:
        1. Spatial search (PostGIS) ‚Üí T·∫§T C·∫¢ ƒë·ªãa ƒëi·ªÉm g·∫ßn (>= 50), c√≥ th·ªÉ l·ªçc theo th·ªùi gian
        2. Semantic search (Qdrant) ‚Üí Top 10 ƒë·ªãa ƒëi·ªÉm ph√π h·ª£p nh·∫•t
        3. Route building (Greedy) ‚Üí Top 3 l·ªô tr√¨nh t·ªët nh·∫•t, validate th·ªùi gian m·ªü c·ª≠a
        
        Args:
            latitude: Vƒ© ƒë·ªô user
            longitude: Kinh ƒë·ªô user
            transportation_mode: Ph∆∞∆°ng ti·ªán di chuy·ªÉn
            semantic_query: Query ng·ªØ nghƒ©a
            max_time_minutes: Th·ªùi gian t·ªëi ƒëa (ph√∫t)
            target_places: S·ªë ƒë·ªãa ƒëi·ªÉm m·ªói l·ªô tr√¨nh
            max_routes: S·ªë l·ªô tr√¨nh t·ªëi ƒëa
            top_k_semantic: S·ªë ƒë·ªãa ƒëi·ªÉm t·ª´ semantic search
            customer_like: T·ª± ƒë·ªông th√™m "Culture & heritage" n·∫øu ch·ªâ c√≥ "Food & Local Flavours"
            current_datetime: Th·ªùi ƒëi·ªÉm hi·ªán t·∫°i c·ªßa user (None = kh√¥ng l·ªçc theo th·ªùi gian)
            
        Returns:
            Dict ch·ª©a routes (top 3 l·ªô tr√¨nh) v√† metadata, bao g·ªìm th√¥ng tin validate th·ªùi gian
        """
        try:
            total_start = time.time()
            
            # 1. Spatial + Semantic search (h·ªó tr·ª£ nhi·ªÅu queries)
            # Pass current_datetime v√† max_time_minutes ƒë·ªÉ l·ªçc POI theo th·ªùi gian
            search_result = self.search_combined_multi_queries(
                latitude=latitude,
                longitude=longitude,
                transportation_mode=transportation_mode,
                semantic_query=semantic_query,
                top_k_semantic=top_k_semantic,
                customer_like=customer_like,
                current_datetime=current_datetime,
                max_time_minutes=max_time_minutes
            )
            
            if search_result["status"] != "success":
                return {
                    "status": "error",
                    "error": "Search failed",
                    "search_error": search_result.get("error"),
                    "routes": []
                }
            
            semantic_places = search_result.get("results", [])
            
            if not semantic_places:
                return {
                    "status": "success",
                    "message": "No places found",
                    "query": semantic_query,
                    "spatial_info": search_result.get("spatial_info", {}),
                    "routes": []
                }
            
            # 2. X√¢y d·ª±ng l·ªô tr√¨nh v·ªõi validation th·ªùi gian m·ªü c·ª≠a
            print(f"\nüîç Step 3: Building routes from {len(semantic_places)} places...")
            route_start = time.time()
            
            user_location = (latitude, longitude)
            routes = self.route_builder.build_routes(
                user_location=user_location,
                places=semantic_places,
                transportation_mode=transportation_mode,
                max_time_minutes=max_time_minutes,
                target_places=target_places,
                max_routes=max_routes,
                current_datetime=current_datetime  # Pass datetime ƒë·ªÉ validate opening hours
            )
            
            route_time = time.time() - route_start
            total_time = time.time() - total_start
            
            print(f"‚è±Ô∏è  Route building: {route_time:.3f}s")
            print(f"‚è±Ô∏è  Total execution time: {total_time:.3f}s")
            print(f"‚úÖ Generated {len(routes)} route(s)")
            
            # L·∫•y timing detail t·ª´ search result
            search_timing = search_result.get("timing_detail", {})
            spatial_time = search_result.get("spatial_info", {}).get("spatial_execution_time", 0)
            
            return {
                "status": "success",
                "query": semantic_query,
                "user_location": {
                    "latitude": latitude,
                    "longitude": longitude
                },
                "spatial_info": search_result.get("spatial_info", {}),
                "semantic_places_count": len(semantic_places),
                "total_execution_time_seconds": round(total_time, 3),
                "timing_breakdown": {
                    "spatial_search_seconds": round(spatial_time, 3),
                    "embedding_seconds": search_timing.get("embedding_seconds", 0),
                    "qdrant_search_seconds": search_timing.get("qdrant_search_seconds", 0),
                    "db_query_seconds": search_timing.get("db_query_seconds", 0),
                    "route_building_seconds": round(route_time, 3),
                    "total_search_seconds": round(search_result.get("total_execution_time_seconds", 0), 3)
                },
                "routes": routes
            }
            
        except Exception as e:
            import traceback
            print(f"‚ùå Error in search_combined_with_routes: {str(e)}")
            print(traceback.format_exc())
            return {
                "status": "error",
                "error": str(e),
                "routes": []
            }
